			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Evelyn Gillie <egillie@stanford.edu>
Peter Pham <ptpham@stanford.edu>
Diego Pontoriero <dpontori@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct timer_sleeping_thread 
{
  int64_t wakeup_time;
  struct thread *t;
  struct list_elem elem;
};

Struct representing a sleeping thread.  wakeup_time is the earliest tick
that this thread can wake up.

static struct list timer_sleeping_threads;
List of current sleeping threads, managed by the timer.  This list is
ordered by wakeup times, with the soonest wake-up times at the front of
the list.


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

In timer_sleep(), we create a timer_sleeping_thread struct for the current
thread, and calculate the earliest wake up time (in ticks).  We then add
this to the global list of sleeping threads, and block the thread.


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The global list of sleeping threads is ordered, with threads with the
soonest wake-up times at the front.  The time interrupt handler only has
to look at the head of the list, check to see if the wake-up time for that
thread has passed, and if it has: wake up that thread, and traverse the
list until we see a thread whose wakeup time has not passed.  At most, the
interrupt handler examines one thread which does not need to be woken,
making the runtime O(number of threads that need to be woken + 1).

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Wherever we traverse, insert into, or delete from our data structures
listed in A1, we disable interrupts, so reads/writes are atomic and
uncorrupted.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Interrupts are disabled in the critical sections of timer_sleep, so no
races can occur.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We first considered storing the wait times in the sleeping thread structs,
but we would have needed to decrement the remaining wait time at every
timer interrupt, an O(n) traversal over timer_sleeping_threads.  Our
implementation instead stores the earliest possible wakeup time, which is
absolute and does not need updates.



			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


In thread.h:

  int effective_priority;
	The effective priority of a thread, which takes into priorities
	donated by other threads.

  struct list priority_holding; 
	A list of locks that this threads holds.

  struct lock *priority_waiting;
	A lock, if any, that this thread is waiting on

In sync.h:
  struct list_elem priority_holder; 
	A list element for a thread's priority_holding list

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

		T1		T2	T3		T4
		\		/	\		/
		 \	   /	 \	   /
		  \	  /		  \   /			- T1 and T2 are waiting on L1
			L1			L2			- T2 and T3 are waiting on L2
			|			|			
			T5			T6			-L1 is held by T5, L2 by T6
			\			/
			 \		   /
			  \		  /
			   \	 /
				  L3				- T5 and T6 are waiting on L3
				  |
				  T7				- L3 is held by T7

Starting at the top: T1 and T2 store L1 in their "priority_waiting" field
(and T3, T4 store L2).	L1 stores T1, T2 in its waiters list, and T5 in
its holder field. 



---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

	Whenever we wake up a thread on a waiters list, we search for the
	thread with the highest effective priority.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
	
	In lock_acquire, if a new thread starts waiting on a lock, we check
	whether its priority is higher than the effective priority of that
	lock's holder.L1's holder, T5.  If it is, we call
	set_effective_priority(lock's holder, priority of current thread);
	set_effective_priority (in addition to setting the effective priority)
	checks to see if the lock's holder is waiting on any locks, and will
	recursively call set_effective_priority on that lock's holder if its
	priority should be propogated.
	

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

	We remove the lock from the list of locks held by the current thread,
	and recalculate the effective priority.  The effective priority
	calculation takes the max of the thread's original priority
	(non-donated), and any priority donations from locks it holds
	(excluding the lock we just removed from its holdings list).

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

When we set a thread's priority, we need to compare it to any potential
donated priorities and compute the max of these priorities.  If, after we
compute the max priority, another thread donates its priority to us, the
just-computed maximum is now stale, and we incorrectly set our priority to
this stale value.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We first planned on keeping the lists of waiting threads and the ready
queue ordered by priority, but decided on keeping the lists unordered and
selecting the thread with the highest priority at retrieval time.  The
bookkeeping involved with keeping the lists ordered unnecessarily
complicated our design, because we would have needed to resort every time
we updated a thread's priority, even indirectly through priority
donations, which might be nested.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:


timer  recent_cpu		priority		  thread
ticks   A   B   C   A		B		C	  to run
-----  --  --  --	--		--		--	  ------
0		0	0	0	63.00	61.00	59.00	A
4		4	0	0	62.00	61.00	59.00	A
8		8	0	0	61.00	61.00	59.00	A
12		12	0	0	60.00	61.00	59.00	B
16		12	4	0	60.00	60.00	59.00	B
20		12	8	0	60.00	59.00	59.00	A
24		16	8	0	59.00	59.00	59.00	A
28		20	8	0	58.00	59.00	59.00	C
32		20	8	4	58.00	59.00	58.00	B
36		20	12	4	58.00	58.00	58.00	B

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
